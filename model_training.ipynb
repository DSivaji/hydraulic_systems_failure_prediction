{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://medium.com/mlearning-ai/all-8-types-of-time-series-classification-methods-2c8e4b323ea2#bd12\n",
    "\n",
    "For any usuall classsification problem, we need to have some set of features, but in our case we\n",
    "have different time series, so our first taks is to convert these time series into features. \n",
    "\n",
    "Transformations: \n",
    "- Lienar transformations using PCA: As taken from different thoughts from\n",
    "[here](https://www.linkedin.com/advice/0/what-advantages-disadvantages-using-pca), we are ingnoring\n",
    "exploring PCA on time series.\n",
    "- Non-Linear transformations like T-SNE: \n",
    "  - T-SNE is a technique used for visual the data, it does not learn any function from the original\n",
    "  space to the new (lower) dimensional one. so this technique is not sutibale for feature\n",
    "  extraction. Please refer the discussion\n",
    "  [here](https://stats.stackexchange.com/questions/340175/why-is-t-sne-not-used-as-a-dimensionality-reduction-technique-for-clustering-or)\n",
    "  - Auto encoders are a good options, we will do this in later sections.\n",
    "- Latent Space Feaure extractions\n",
    "  - tsfresh\n",
    "  - pyts\n",
    "  - cesium\n",
    "  \n",
    "\n",
    "Note: \n",
    "- Please be aware, tsfresh feature extraction is a bit slow.\n",
    "- We are using only default setting for feature extraction, Please refere documentation for details and advanced settings for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.hydraulic.config import DATA_PATH, SEPERATOR, PROFILE_COLUMNS, FILES_NAMES, DATA_OUTPUT_PATH\n",
    "from tslearn.utils import to_sktime_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target data array shape : (2205, 5)\n",
      "temperature - TS1 : (2205, 60)\n",
      "temperature - TS2 : (2205, 60)\n",
      "temperature - TS3 : (2205, 60)\n",
      "temperature - TS4 : (2205, 60)\n",
      "vibration - VS1 : (2205, 60)\n",
      "cooling_efficiency - CE : (2205, 60)\n",
      "cooling_power - CP : (2205, 60)\n",
      "efficiency_factor - SE : (2205, 60)\n"
     ]
    }
   ],
   "source": [
    "target = pd.read_csv(F'{DATA_PATH}/profile.txt',sep=SEPERATOR, names=PROFILE_COLUMNS)\n",
    "print(f\"Target data array shape : {target.shape}\")\n",
    "\n",
    "# Load data and converting data into TS arrays\n",
    "sktime_df = pd.DataFrame()\n",
    "for sensor_type, data_file_names_list in FILES_NAMES.items():\n",
    "    for file_name in data_file_names_list:\n",
    "        if sensor_type in ['pressure', 'motor_power', 'volume_flow']:\n",
    "            pass\n",
    "        else:\n",
    "            # read txt file\n",
    "            ts_data = pd.read_csv(f'./data/{file_name}.txt', sep='\\t', header=None)\n",
    "            print(f\"{sensor_type} - {file_name} : {ts_data.shape}\")\n",
    "            # transform column data to TS array for TSKmeansClustring.\n",
    "            sktime_df[f\"{sensor_type}_{file_name}\"] = to_sktime_dataset(ts_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_idx, test_idx = train_test_split(sktime_df.index, random_state=9)\n",
    "\n",
    "X_train, y_train = sktime_df.loc[train_idx], target.loc[train_idx]\n",
    "X_test, y_test = sktime_df.loc[test_idx], target.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X Shape: (1653, 8)\n",
      "Train y Shape: (1653, 5)\n",
      "Sample Train X:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_TS1</th>\n",
       "      <th>temperature_TS2</th>\n",
       "      <th>temperature_TS3</th>\n",
       "      <th>temperature_TS4</th>\n",
       "      <th>vibration_VS1</th>\n",
       "      <th>cooling_efficiency_CE</th>\n",
       "      <th>cooling_power_CP</th>\n",
       "      <th>efficiency_factor_SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0     54.414\n",
       "1     54.340\n",
       "2     54.309\n",
       "3     5...</td>\n",
       "      <td>0     58.887\n",
       "1     58.871\n",
       "2     58.871\n",
       "3     5...</td>\n",
       "      <td>0     55.754\n",
       "1     55.754\n",
       "2     55.762\n",
       "3     5...</td>\n",
       "      <td>0     49.484\n",
       "1     49.496\n",
       "2     49.445\n",
       "3     4...</td>\n",
       "      <td>0     0.653\n",
       "1     0.688\n",
       "2     0.711\n",
       "3     0.72...</td>\n",
       "      <td>0     20.376\n",
       "1     20.551\n",
       "2     20.483\n",
       "3     2...</td>\n",
       "      <td>0     1.555\n",
       "1     1.560\n",
       "2     1.566\n",
       "3     1.58...</td>\n",
       "      <td>0     65.230\n",
       "1      0.000\n",
       "2      0.000\n",
       "3      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>0     46.793\n",
       "1     46.727\n",
       "2     46.621\n",
       "3     4...</td>\n",
       "      <td>0     51.844\n",
       "1     51.816\n",
       "2     51.797\n",
       "3     5...</td>\n",
       "      <td>0     48.848\n",
       "1     48.859\n",
       "2     48.895\n",
       "3     4...</td>\n",
       "      <td>0     42.328\n",
       "1     42.320\n",
       "2     42.254\n",
       "3     4...</td>\n",
       "      <td>0     0.591\n",
       "1     0.626\n",
       "2     0.670\n",
       "3     0.68...</td>\n",
       "      <td>0     26.098\n",
       "1     26.055\n",
       "2     26.375\n",
       "3     2...</td>\n",
       "      <td>0     1.697\n",
       "1     1.698\n",
       "2     1.715\n",
       "3     1.70...</td>\n",
       "      <td>0     68.879\n",
       "1      0.000\n",
       "2      0.000\n",
       "3      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       temperature_TS1  \\\n",
       "246  0     54.414\n",
       "1     54.340\n",
       "2     54.309\n",
       "3     5...   \n",
       "847  0     46.793\n",
       "1     46.727\n",
       "2     46.621\n",
       "3     4...   \n",
       "\n",
       "                                       temperature_TS2  \\\n",
       "246  0     58.887\n",
       "1     58.871\n",
       "2     58.871\n",
       "3     5...   \n",
       "847  0     51.844\n",
       "1     51.816\n",
       "2     51.797\n",
       "3     5...   \n",
       "\n",
       "                                       temperature_TS3  \\\n",
       "246  0     55.754\n",
       "1     55.754\n",
       "2     55.762\n",
       "3     5...   \n",
       "847  0     48.848\n",
       "1     48.859\n",
       "2     48.895\n",
       "3     4...   \n",
       "\n",
       "                                       temperature_TS4  \\\n",
       "246  0     49.484\n",
       "1     49.496\n",
       "2     49.445\n",
       "3     4...   \n",
       "847  0     42.328\n",
       "1     42.320\n",
       "2     42.254\n",
       "3     4...   \n",
       "\n",
       "                                         vibration_VS1  \\\n",
       "246  0     0.653\n",
       "1     0.688\n",
       "2     0.711\n",
       "3     0.72...   \n",
       "847  0     0.591\n",
       "1     0.626\n",
       "2     0.670\n",
       "3     0.68...   \n",
       "\n",
       "                                 cooling_efficiency_CE  \\\n",
       "246  0     20.376\n",
       "1     20.551\n",
       "2     20.483\n",
       "3     2...   \n",
       "847  0     26.098\n",
       "1     26.055\n",
       "2     26.375\n",
       "3     2...   \n",
       "\n",
       "                                      cooling_power_CP  \\\n",
       "246  0     1.555\n",
       "1     1.560\n",
       "2     1.566\n",
       "3     1.58...   \n",
       "847  0     1.697\n",
       "1     1.698\n",
       "2     1.715\n",
       "3     1.70...   \n",
       "\n",
       "                                  efficiency_factor_SE  \n",
       "246  0     65.230\n",
       "1      0.000\n",
       "2      0.000\n",
       "3      ...  \n",
       "847  0     68.879\n",
       "1      0.000\n",
       "2      0.000\n",
       "3      ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Train X Shape: {X_train.shape}\")\n",
    "print(f\"Train y Shape: {y_train.shape}\")\n",
    "print(f\"Sample Train X:\")\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Train Y:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cooler</th>\n",
       "      <th>valve</th>\n",
       "      <th>pump_lekage</th>\n",
       "      <th>accumulator</th>\n",
       "      <th>stable_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cooler  valve  pump_lekage  accumulator  stable_flag\n",
       "246       3    100            2          130            0\n",
       "847      20    100            0           90            1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Sample Train Y:\")\n",
    "y_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# kind of feature selection\n",
    "from sktime.transformations.panel.channel_selection import ElbowClassPairwise\n",
    "\n",
    "# feature transfomers \n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sktime.transformations.panel.tsfresh import TSFreshFeatureExtractor\n",
    "from sktime.transformations.panel.catch22 import Catch22\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current transformers accepts all sensons should be of same size. so excluding some sensors in the\n",
    "model. Try out different transfamations to find out best performance of the final model.\n",
    "\n",
    "Usually channel selection makes training and infrence processing much faster.\n",
    "\n",
    "\n",
    "### ROCKET Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding sensors with have time series lent is not equal to 60\n",
    "exclude_sensors = [i for i in X_train.columns if i.split('_')[0] in ['pressure', 'motor', 'volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy for cooler : 0.9909420289855072\n",
      "Model Accuracy for valve : 0.8894927536231884\n",
      "Model Accuracy for pump_lekage : 0.7934782608695652\n",
      "Model Accuracy for accumulator : 0.8822463768115942\n",
      "Model Accuracy for stable_flag : 0.9094202898550725\n"
     ]
    }
   ],
   "source": [
    "rocket_pipeline = MultiOutputClassifier(\n",
    "    make_pipeline(\n",
    "        ElbowClassPairwise(), # channel selection, kind of seansor selection for training\n",
    "        Rocket(num_kernels=10000, n_jobs=-1, random_state=200), # Feature extranction transformations\n",
    "        RandomForestClassifier(random_state=200)  # regular random forest classifier\n",
    "    )\n",
    ")\n",
    "\n",
    "rocket_pipeline.fit(X_train, y_train)\n",
    "test_predictions_ = rocket_pipeline.predict(X_test)\n",
    "for i, v in enumerate(y_test.columns):\n",
    "    print(f\"Model Accuracy for {v} : {accuracy_score(y_test[v].values,test_predictions_[:,i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy for cooler : 0.9981884057971014\n",
      "Model Accuracy for valve : 0.8768115942028986\n",
      "Model Accuracy for pump_lekage : 0.9818840579710145\n",
      "Model Accuracy for accumulator : 0.9655797101449275\n",
      "Model Accuracy for stable_flag : 0.9293478260869565\n"
     ]
    }
   ],
   "source": [
    "catch22_pipeline = MultiOutputClassifier(\n",
    "    make_pipeline(\n",
    "        ElbowClassPairwise(), # channel selection, kind of seansor selection for training\n",
    "        Catch22(n_jobs=-1, catch24=True), # Feature extranction transformations\n",
    "        RandomForestClassifier(random_state=200)  # regular random forest classifier\n",
    "    ) \n",
    ")\n",
    "\n",
    "catch22_pipeline.fit(X_train, y_train)\n",
    "test_predictions_ = catch22_pipeline.predict(X_test)\n",
    "for i, v in enumerate(y_test.columns):\n",
    "    print(f\"Model Accuracy for {v} : {accuracy_score(y_test[v].values, test_predictions_[:,i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSFresh transformations\n",
    "\n",
    "Randonly this transformations are not working while in prediction part. So need to validate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 60/60 [00:22<00:00,  2.63it/s]\n",
      "Feature Extraction: 100%|██████████| 60/60 [00:04<00:00, 12.84it/s]\n",
      "Feature Extraction: 100%|██████████| 60/60 [00:05<00:00, 11.59it/s]\n",
      "Feature Extraction: 100%|██████████| 60/60 [00:19<00:00,  3.03it/s]\n",
      "Feature Extraction: 100%|██████████| 60/60 [00:04<00:00, 12.87it/s]\n",
      "Feature Extraction: 100%|██████████| 60/60 [00:08<00:00,  6.76it/s]\n",
      "Feature Extraction: 100%|██████████| 56/56 [00:03<00:00, 16.82it/s]\n",
      "Feature Extraction: 100%|██████████| 56/56 [00:02<00:00, 18.78it/s]\n",
      "Feature Extraction: 100%|██████████| 60/60 [00:07<00:00,  8.09it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m tsfresh_pipeline \u001b[39m=\u001b[39m MultiOutputClassifier(\n\u001b[1;32m      2\u001b[0m     make_pipeline(\n\u001b[1;32m      3\u001b[0m         ElbowClassPairwise(), \u001b[39m# channel selection, kind of seansor selection for training\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m tsfresh_pipeline\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> 14\u001b[0m test_predictions_ \u001b[39m=\u001b[39m tsfresh_pipeline\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(y_test\u001b[39m.\u001b[39mcolumns):\n\u001b[1;32m     16\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel Accuracy for \u001b[39m\u001b[39m{\u001b[39;00mv\u001b[39m}\u001b[39;00m\u001b[39m : \u001b[39m\u001b[39m{\u001b[39;00maccuracy_score(y_test[v]\u001b[39m.\u001b[39mvalues,\u001b[39m \u001b[39mtest_predictions_[:,i])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/sklearn/multioutput.py:248\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    246\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe base estimator should implement a predict method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 248\u001b[0m y \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    249\u001b[0m     delayed(e\u001b[39m.\u001b[39;49mpredict)(X) \u001b[39mfor\u001b[39;49;00m e \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_\n\u001b[1;32m    250\u001b[0m )\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(y)\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/sklearn/pipeline.py:481\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    480\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39mtransform(Xt)\n\u001b[0;32m--> 481\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msteps[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpredict(Xt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpredict_params)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    800\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 820\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[1;32m    822\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    823\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    860\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    861\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[1;32m    864\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    865\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 602\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    603\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[1;32m    604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/sklearn/base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    485\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[1;32m    490\u001b[0m ):\n\u001b[1;32m    491\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \n\u001b[1;32m    493\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    550\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    551\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    552\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    553\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds_activity/lib/python3.8/site-packages/sklearn/base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    477\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    478\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    479\u001b[0m     )\n\u001b[0;32m--> 481\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tsfresh_pipeline = MultiOutputClassifier(\n",
    "    make_pipeline(\n",
    "        ElbowClassPairwise(), # channel selection, kind of seansor selection for training\n",
    "        TSFreshFeatureExtractor(\n",
    "            default_fc_parameters = \"efficient\",\n",
    "            show_warnings=False,\n",
    "            n_jobs=-1\n",
    "        ), # Feature extranction transformations\n",
    "        RandomForestClassifier(random_state=200)  # regular random forest classifier\n",
    "    )\n",
    ")\n",
    "\n",
    "tsfresh_pipeline.fit(X_train, y_train)\n",
    "test_predictions_ = tsfresh_pipeline.predict(X_test)\n",
    "for i, v in enumerate(y_test.columns):\n",
    "    print(f\"Model Accuracy for {v} : {accuracy_score(y_test[v].values, test_predictions_[:,i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_activity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "965b0a8d803aff29bca95884998985ad5c7f9386dcf9b8c90bf9f5e4c9b5c171"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
